{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb6ba8c-3b92-4cc3-a250-1f467bc17ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "with open(\"conda_requirements.txt\", \"w\") as crf:\n",
    "    crf.truncate(0)\n",
    "    with open(\"pip_requirements.txt\", \"w\") as prf:\n",
    "        prf.truncate(0)\n",
    "        with open('all_requirements.txt', 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                pypi_check = re.search(r'(.+)=pypi.*', line)\n",
    "                if pypi_check:\n",
    "                    print(re.sub(r'=', '==', pypi_check.group(1)).strip(), file=prf)\n",
    "                else:\n",
    "                    print(line.strip(), file=crf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db82eb6a-2770-4ea5-a368-4a305c0fdc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      " - nvidia\n",
      " - pytorch\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y --file conda_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f0f7251-67f4-4647-ac79-85c6778ecb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet -r pip_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc02874-0fa9-4a37-ac53-a0a07bb528be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import itertools\n",
    "import pdb\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "# setting device on GPU if available, else CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb856e76-1074-406f-99df-535a9bcea753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\git_repos\\\\2024_05_12_speaker_agent_sizes'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "original_working_directory = os.getcwd()\n",
    "original_working_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "351d19cb-8ae2-459b-ab10-4cfd3b6e1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(original_working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3c55ce-6af9-4c9b-ac2d-304a92c2c99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(module):\n",
    "    parameter_count = 0\n",
    "    for params in module.parameters():\n",
    "        parameter_count += params.numel()\n",
    "    return (parameter_count, len(str(parameter_count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68cb976b-2283-4ca2-a0b1-e93922fc60fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need this a few times\n",
    "\n",
    "from transformers import ResNetForImageClassification\n",
    "\n",
    "resnet = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "params_resnet, _ = count_parameters(resnet)\n",
    "\n",
    "del resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee12fde-5f0f-415b-bbd5-3f96dcd48b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_sizes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd363ac-0b21-40b3-a8f3-7cc68ce38321",
   "metadata": {},
   "source": [
    "# 1. Natural language does not emerge ’naturally’ in multi-agent dialog\n",
    "\n",
    "This paper uses symbollic inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0be0b82-7524-4b57-8e5b-352e92b8a011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments:\n",
      "\t  hiddenSize : 50\n",
      "\t   embedSize : 20\n",
      "\t imgFeatSize : 20\n",
      "\t   qOutVocab : 3\n",
      "\t   aOutVocab : 4\n",
      "\t     dataset : data/64_synthetic.json\n",
      "\t     rlScale : 100.0\n",
      "\t   numRounds : 2\n",
      "\t    remember : False\n",
      "\t negFraction : 0.8\n",
      "\t   batchSize : 1000\n",
      "\t   numEpochs : 1000000\n",
      "\tlearningRate : 0.001\n",
      "\t      useGPU : False\n",
      "Answerer(\n",
      "  (inNet): Embedding(7, 20)\n",
      "  (outNet): Linear(in_features=50, out_features=4, bias=True)\n",
      "  (imgNet): Embedding(12, 20)\n",
      "  (rnn): LSTMCell(80, 50)\n",
      ")\n",
      "Questioner(\n",
      "  (inNet): Embedding(16, 20)\n",
      "  (outNet): Linear(in_features=50, out_features=3, bias=True)\n",
      "  (rnn): LSTMCell(20, 50)\n",
      "  (predictRNN): LSTMCell(20, 50)\n",
      "  (predictNet): Linear(in_features=50, out_features=12, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(29885, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('lang-emerge')\n",
    "\n",
    "# Based on what is in train.py!\n",
    "\n",
    "from chatbots import Team\n",
    "from dataloader import Dataloader\n",
    "import options # sets the default hyperparameters etc.\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# read the command line options\n",
    "options = options.read()\n",
    "#------------------------------------------------------------------------\n",
    "# setup experiment and dataset\n",
    "#------------------------------------------------------------------------\n",
    "data = Dataloader(options)\n",
    "numInst = data.getInstCount()\n",
    "\n",
    "params = data.params\n",
    "# append options from options to params\n",
    "for key, value in options.items():\n",
    "  params[key] = value\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# build agents, and setup optmizer\n",
    "#------------------------------------------------------------------------\n",
    "team = Team(params)\n",
    "\n",
    "speaker = team.qBot\n",
    "\n",
    "params, order = count_parameters(speaker)\n",
    "parameter_sizes.append({\n",
    "    'title': 'Natural language does not emerge ’naturally’ in multi-agent dialog',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ece762b-3d72-4b4b-8410-106a75303878",
   "metadata": {},
   "source": [
    "## 2. Emergence of Grounded Compositional Language in Multi-Agent Populations\n",
    "\n",
    "This paper uses symbollic inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e940afa-0728-4935-8fa9-fde5fec80bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1870105, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('emergent-language/modules')\n",
    "\n",
    "from agent import AgentModule\n",
    "from configs import default_agent_config\n",
    "\n",
    "speaker = AgentModule(default_agent_config)\n",
    "\n",
    "params, order = count_parameters(speaker)\n",
    "parameter_sizes.append({\n",
    "    'title': 'Emergence of Grounded Compositional Language in Multi-Agent Populations',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de02125c-fac8-43a6-b4e9-3483aee316d8",
   "metadata": {},
   "source": [
    "## 3. Emergence of Communication in an Interactive World with Consistent Speakers\n",
    "\n",
    "This speaker agent uses images as input and the CNN is initialised as part of the speaker agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75478047-c791-49e5-aac6-83588a461779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45253, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('emergence-communication-cco/agent')\n",
    "\n",
    "import agent_type\n",
    "from vec_agent import VecAgent\n",
    "\n",
    "speaker = VecAgent(\n",
    "    agent_type.AgentType.speaker,\n",
    "    acting=True # this parameter does not affect the speaker agent size\n",
    ")\n",
    "\n",
    "params, order = count_parameters(speaker.model)\n",
    "parameter_sizes.append({\n",
    "    'title': 'Emergence of Communication in an Interactive World with Consistent Speakers',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a64496e-878b-4b0e-bd02-a71e737bb73a",
   "metadata": {},
   "source": [
    "## 4. Compositional Obverter Communication Learning From Raw Visual Input\n",
    "\n",
    "This speaker agent uses images as input and the CNN is initialised as part of the speaker agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c156593c-a89e-4c07-b055-2dc5cc7f3f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64676, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('obverter')\n",
    "\n",
    "from model import ConvModel # Not just a CNN but an agent\n",
    "\n",
    "speaker = ConvModel(\n",
    "    5 # vocabulary size, taken from the paper\n",
    ")\n",
    "\n",
    "params, order = count_parameters(speaker)\n",
    "parameter_sizes.append({\n",
    "    'title': 'Compositional Obverter Communication Learning From Raw Visual Input',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28743794-029a-4269-93aa-1f4a13641e87",
   "metadata": {},
   "source": [
    "## 5. Emergence of Compositional Language with Deep Generational Transmission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b18d0f-2ff1-43fe-9a86-8b02ece38d4f",
   "metadata": {},
   "source": [
    "We have to temporarily install parlai for this one, then uninstall it, then clean up after ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dda0921-c4c2-4b9c-b031-9ad19fc81ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.42.4 requires huggingface-hub<1.0,>=0.23.2, but you have huggingface-hub 0.17.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install parlai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01fbc68f-b6f5-493c-a0d7-14c4aa5c1588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107956, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('evolang')\n",
    "\n",
    "from bots import Questioner\n",
    "\n",
    "params, order = count_parameters(Questioner(\n",
    "    { \n",
    "        'q_out_vocab': 64, # Max seen in run.py\n",
    "        'a_out_vocab': 64, # Max seen in run.py\n",
    "        'task_vocab': 6, # Defined in train.py as len(dataset.task_defn) which based on the datasets folder is typically 6\n",
    "        'embed_size': 20, # default from options.py\n",
    "        'hidden_size': 100, # default from options.py\n",
    "        'props': {'shapes': [0, 1, 2, 3], 'styles': [0, 1, 2, 3], 'colors': [0, 1, 2, 3]} # From the json in the datasets folder\n",
    "    }\n",
    "))\n",
    "parameter_sizes.append({\n",
    "    'title': 'Emergence of Compositional Language with Deep Generational Transmission',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8c75f-a3e7-4e40-9b95-56c9f3bcc0f9",
   "metadata": {},
   "source": [
    "Reinstall newer version of attrs so that everything else can run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8de8fa9-87a8-409e-b9ca-87a957aadf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y parlai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11ec3369-48dc-4a7c-8c9a-ea2d884bf3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(original_working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fe54e77-00e7-4ec2-8963-a87bcbf10ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      " - nvidia\n",
      " - pytorch\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y --file conda_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82e59a4c-852a-4e3c-97cf-74a834d62b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet -r pip_requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6f44e2-698c-4188-b75a-49635800ea39",
   "metadata": {},
   "source": [
    "## 6. The Emergence of Compositional Languages for Numeric Concepts Through Iterated Learning in Neural Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc5397d8-4dc0-4390-8fbe-2446518134cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6264858, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The paper says they use an LSTM speaker like Havrylov and Titov (2017) \"Emergence of language with multi-agent game...\"\n",
    "# Havrylov and Titov say they use an LSTM with hidden size 512 and vocabulary 10000\n",
    "# And also a LeNet for embedding images\n",
    "\n",
    "class HavrylovNet(nn.Module):\n",
    "    # Based on https://github.com/lychengrex/LeNet-5-Implementation-Using-Pytorch/blob/master/LeNet-5%20Implementation%20Using%20Pytorch.ipynb\n",
    "\n",
    "    # network structure\n",
    "    def __init__(self):\n",
    "        super(HavrylovNet, self).__init__()\n",
    "        self.rnn = nn.LSTM(\n",
    "            10, # LSTM input size is LeNet output size, i.e. 10\n",
    "            512\n",
    "        )\n",
    "        self.projector = nn.Linear(512, 10000)\n",
    "\n",
    "    def forward(self, img, wrd):\n",
    "        '''\n",
    "        One forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: input\n",
    "        '''\n",
    "        return F.softmax(self.projector(self.rnn(x)))\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "\n",
    "    # network structure\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        One forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: input\n",
    "        '''\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        '''\n",
    "        Get the number of features in a batch of tensors `x`.\n",
    "        '''\n",
    "        size = x.size()[1:]\n",
    "        return np.prod(size)\n",
    "\n",
    "params, order = count_parameters(torch.nn.Sequential(LeNet(), HavrylovNet()))\n",
    "parameter_sizes.append({\n",
    "    'title': 'The Emergence of Compositional Languages for Numeric Concepts Through Iterated Learning in Neural Agents',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40fa5a3-83c6-40e6-a179-9d7c10a075a9",
   "metadata": {},
   "source": [
    "## 7. Ease-of-Teaching and Language Structure from Emergent Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4396d032-3a2d-48e0-a0ba-2c5f841fb39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46108, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('Ease-of-teaching-and-language-structure/code')\n",
    "\n",
    "import argparse\n",
    "# The initial arguments from parse are copied from parse.py\n",
    "def parse():\n",
    "    parser = argparse.ArgumentParser(description='Referential game settings')\n",
    "\n",
    "    parser.add_argument('--gpu', type=int, default=0, help='which gpu if we use gpu')\n",
    "    parser.add_argument('--fname', type=str, default='test', help='folder name to save results')\n",
    "    parser.add_argument('--seed', type=int, default=0)\n",
    "    parser.add_argument('--jupyter', action='store_true') \n",
    "    parser.add_argument('--slambda', type=float, default=0.1, help='speaker regularization hyperparameter')\n",
    "    parser.add_argument('--rlambda', type=float, default=0.1, help='listener regularization hyperparameter')\n",
    "    parser.add_argument('--receiverNum', type=int, default=1, help='number of listeners in the population')\n",
    "    parser.add_argument('--topk', type=int, default=3, help='number of top messages when we probe language')\n",
    "    parser.add_argument('--evaluateSize', type=int, default=1000, help='the batch size of test objects when not enumeration')\n",
    "    args_dict = vars(parser.parse_args([])) # convert python object to dict\n",
    "    return args_dict\n",
    "\n",
    "args = parse()  # parsed argument from CLI\n",
    "args['device'] = torch.device(\"cuda:\" + str(args['gpu']) if torch.cuda.is_available() else \"cpu\")\n",
    "if not os.path.exists(args['fname']):\n",
    "    os.makedirs(args['fname'])\n",
    "\n",
    "# dataset hyperparameters\n",
    "args['numColors'] = 8 # based on the paper https://arxiv.org/pdf/1906.02403\n",
    "args['numShapes'] = 4  # based on the paper https://arxiv.org/pdf/1906.02403\n",
    "args['attrSize'] = args['numColors'] + args['numShapes']  # colors + shapes\n",
    "\n",
    "# game settings\n",
    "args['vocabSize'] = 8  # based on the paper https://arxiv.org/pdf/1906.02403\n",
    "args['messageLen'] = 2  # based on the paper https://arxiv.org/pdf/1906.02403\n",
    "args['distractNum'] = 5  # including targets\n",
    "\n",
    "# training hyperparameters\n",
    "args['batchSize'] = 100  # total train data = batchSize * numIters\n",
    "args['sLearnRate'] = 0.001  \n",
    "args['rLearnRate'] = 0.001  \n",
    "\n",
    "args['trainIters'] = 300000 # training\n",
    "args['resetNum'] = 50  \n",
    "args['resetIter'] = args['trainIters'] // args['resetNum']  # life of a receiver: 6K\n",
    "args['deterResetNums'] = 30\n",
    "args['deterResetIter'] = 1000\n",
    "\n",
    "# population of receivers training\n",
    "args['population'] = False\n",
    "\n",
    "# model hyperparameters\n",
    "args['hiddenSize'] = 100  # based on the paper https://arxiv.org/pdf/1906.02403\n",
    "\n",
    "from models import Sender\n",
    "\n",
    "params, order = count_parameters(Sender(args))\n",
    "parameter_sizes.append({\n",
    "    'title': 'Ease-of-Teaching and Language Structure from Emergent Communication',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a2a65-41f6-40d1-b78e-0e15e45e1aed",
   "metadata": {},
   "source": [
    "## 8. Compositional Languages Emerge in a Neural Iterated Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6172b5d-e6bd-45db-83a5-9772fd44aae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73872, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('Neural_Iterated_Learning/models')\n",
    "\n",
    "if \"model\" in sys.modules:\n",
    "    del sys.modules[\"model\"] # we used model before from a different repository!\n",
    "from model import SpeakingAgent\n",
    "\n",
    "os.chdir('../utils')\n",
    "import conf\n",
    "\n",
    "params, order = count_parameters(SpeakingAgent())\n",
    "parameter_sizes.append({\n",
    "    'title': 'Compositional Languages Emerge in a Neural Iterated Learning Model',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a2854-4372-4311-a565-9f8973e34ee5",
   "metadata": {},
   "source": [
    "## 9. Compositionality and Generalization in Emergent Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05c8e3a5-748b-4f0c-905b-fb58f44ca8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153600, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The paper says\n",
    "\n",
    "  Each input i of the reconstruction game is comprised of iatt attributes,\n",
    "  each with ival possible values. We let i_{att} range from 2 to 4 and i_{val}\n",
    "  from 4 to 100. We represent each attribute as a i_{val} one-hot vector. An\n",
    "  input i is given by the concatenation of its attributes. \n",
    "\n",
    "  ...\n",
    "\n",
    "  Both agents are implemented as single-layer GRU cells (Cho et al., 2014)\n",
    "  with hidden states of size 500.\n",
    "  \n",
    "  Sender encodes i in a message m of fixed length c_{len} as follows. First,\n",
    "  a linear layer maps the input vector into the initial hidden state of\n",
    "  Sender. Next, the message is generated symbol-by-symbol by sampling from a\n",
    "  Categorical distribution over the vocabulary cvoc, parameterized by a linear\n",
    "  mapping from Sender’s hidden state.\n",
    "\n",
    "  In practice, we fix [vocabulary size to 100].\n",
    "\"\"\"\n",
    "\n",
    "class CompGenNet(nn.Module):\n",
    "\n",
    "    # network structure\n",
    "    def __init__(self):\n",
    "        super(CompGenNet, self).__init__()\n",
    "        self.fc1   = nn.Linear(400, 500)\n",
    "        self.gru   = nn.GRU(100, 500)\n",
    "        self.fc2   = nn.Linear(500, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        One forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: input\n",
    "        '''\n",
    "        hidden = self.fc1(x)\n",
    "        out, hidden = self.gru(x, hidden)\n",
    "        return self.fc2(out)\n",
    "\n",
    "params, order = count_parameters(CompGenNet())\n",
    "parameter_sizes.append({\n",
    "    'title': 'Compositionality and Generalization in Emergent Languages',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e4912-9131-49ed-b894-ad815b86623a",
   "metadata": {},
   "source": [
    "## 10. Co-evolution of language and agents in referential games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af5969c6-3c98-4d07-b799-33ebd8cda360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1696909, 7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('cultural-evolution-engine/model')\n",
    "\n",
    "from ShapesModels import ShapesSender\n",
    "from visual_module import CNN\n",
    "\n",
    "cnn = CNN(\n",
    "    # paper says \"The linear layer which followed the convolutional layers had output dimensions of 512\"\n",
    "    n_out_features=512\n",
    ")\n",
    "\n",
    "sender = ShapesSender(vocab_size=5, output_len=5, sos_id=0)\n",
    "params, order = count_parameters(torch.nn.Sequential(cnn, sender))\n",
    "parameter_sizes.append({\n",
    "    'title': 'Co-evolution of language and agents in referential games',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84c347d-0c99-416f-8d4e-35d54247c1a2",
   "metadata": {},
   "source": [
    "## 11. Inductive Bias and Language Expressivity in Emergent Communication\n",
    "\n",
    "This repository requires us to install a package from a git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0482c667-2029-4171-a4fe-88a6f11ac3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\git_repos\\2024_05_12_speaker_agent_sizes\\GameBias-EmeCom2020\\modules.py:43: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(m.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(443584, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('GameBias-EmeCom2020')\n",
    "\n",
    "from modules import DspritesSenderCNN\n",
    "\n",
    "params, order = count_parameters(DspritesSenderCNN())\n",
    "parameter_sizes.append({\n",
    "    'title': 'Inductive Bias and Language Expressivity in Emergent Communication',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8352296c-37cd-46dd-8ab8-1304a9ae36b0",
   "metadata": {},
   "source": [
    "## 12. Capacity, Bandwidth, and Compositionality in Emergent Language Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23f964bc-cfa4-4842-9331-f19d979430e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670982, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "os.chdir(original_working_directory)\n",
    "\n",
    "# Read in the file\n",
    "with open('cbc-emecom/main.py', 'r') as file:\n",
    "  filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = filedata.replace('parser.add_argument', '#')\n",
    "\n",
    "# Write the file out again\n",
    "with open('cbc-emecom/main.py', 'w') as file:\n",
    "  file.write(filedata)\n",
    "os.chdir(\"cbc-emecom\")\n",
    "\n",
    "# sys.argv = [\"main.py\", \"--num-binary-messages\", \"24\", \"--num-digits\", \"6\", \"--embedding-size-sender\", \"40\", \"--project-size-sender\", \"60\", \"--num-lstm-sender\", \"300\", \"--num-lstm-receiver\", \"325\", \"--embedding-size-receiver\", \"125\", \"--save-str\", \"<SAVE_STR>\"]\n",
    "\n",
    "from main import CompCap\n",
    "\n",
    "config = {\n",
    "    'device': device,\n",
    "    'num_binary_messages': 24,\n",
    "    'seed': 0,\n",
    "    \n",
    "    # problem size\n",
    "    'batch_size': 100,\n",
    "    'num_digits': 6,\n",
    "    'signature_size': 2,\n",
    "    \n",
    "    # network params\n",
    "    'embedding_size_sender': 40,\n",
    "    'project_size_sender': 60,\n",
    "    'num_lstm_sender': 300,\n",
    "    'num_lstm_receiver': 325,\n",
    "    'embedding_size_receiver': 125,\n",
    "    \n",
    "    # optimization params\n",
    "    'learning_rate': 3e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'output_loss_penalty': 1,\n",
    "    'weight_norm_penalty': 1e-4,\n",
    "    'temp': 1,\n",
    "    'max_iters': 200000,\n",
    "    'train_acc': 0.60,\n",
    "    'trainval_acc': 0.60,\n",
    "    # logging/printing\n",
    "    'trainval_interval': 50,\n",
    "    'model_dir': None,\n",
    "    'save_str': '',\n",
    "    'log_dir': \"./logs\",\n",
    "    'save_dir': \"./models\"\n",
    "}\n",
    "\n",
    "# parameter_count = 0\n",
    "\n",
    "capacity_bandwidth_compositionality = CompCap(config)\n",
    "\n",
    "parameter_count = 0\n",
    "for name, module in capacity_bandwidth_compositionality.named_modules():\n",
    "    if name.startswith('sender'):\n",
    "        for params in module.parameters():\n",
    "            parameter_count += params.numel()\n",
    "\n",
    "params, order = (parameter_count, len(str(parameter_count)))\n",
    "parameter_sizes.append({\n",
    "    'title': 'Capacity, Bandwidth, and Compositionality in Emergent Language Learning',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0137e9d-ea08-4842-8573-170b02bb5dd2",
   "metadata": {},
   "source": [
    "## 13. Emergent Communication at Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba7c1a8c-402c-463d-ba3c-1907efb0f4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params without resnet:  1328870 . Order without resnet:  7\n",
      "Params with resnet:  26885902 . Order with resnet:  8\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The paper says:\n",
    "\n",
    "The speaker’s network architecture is composed of several components to transform the\n",
    "target image x into a message m = (wt)T −1\n",
    "t=0 :\n",
    "• The encoder f is a fixed Resnet-50 architecture that has been previously trained on Ima-\n",
    "genet with the BYOL algorithm. The resulting embedding f (x) is of size 2048.\n",
    "• The RNN hθ used is an LSTM of hidden size 256. Therefore the core state zt,θ is of size\n",
    "512.\n",
    "• The core-state adapter cθ is a linear layer with input size 2048 and an output size of 512 that\n",
    "allows to transform the embedding f (x) into an appropriate core state z−1,θ = cθ (f (x)).\n",
    "We split z−1,θ into two equal parts to obtain the initial hidden state zh,−1,θ and the initial\n",
    "cell state zc,−1,θ .\n",
    "• The word embedder gθ associates to each discrete symbols in W ∪ {sos} an embedding\n",
    "of size 10.\n",
    "• The value head vθ first selects the hidden part zh,t,θ of the core state zt,θ and then applies\n",
    "a linear layer of output size 1.\n",
    "• The policy head πθ first selects the hidden part zh,t,θ of the core state zt,θ and then applies\n",
    "a linear layer of output size |W| to obtain logit\n",
    "\"\"\"\n",
    "\n",
    "class ScaleNet(nn.Module):\n",
    "\n",
    "    # network structure\n",
    "    def __init__(self):\n",
    "        super(ScaleNet, self).__init__()\n",
    "        self.core_state_adapter = nn.Linear(2048, 512)\n",
    "        self.word_embedder = nn.Linear(20, 10)\n",
    "        self.rnn = nn.LSTM(10, 256)\n",
    "        self.value_head = nn.Linear(256, 10)\n",
    "        self.policy_head = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, img, wrd):\n",
    "        '''\n",
    "        One forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: input\n",
    "        '''\n",
    "        x = self.core_state_adapter(x)\n",
    "        return x\n",
    "\n",
    "params, _ = count_parameters(ScaleNet())\n",
    "\n",
    "# This paper uses a resnet to preprocess images to make referents, so it's not\n",
    "#   clear whether we should include the resnet as part of the speaker agent\n",
    "#   size. We'll take two measurements, one for each case\n",
    "\n",
    "order = len(str(params))\n",
    "parameter_sizes.append({\n",
    "    'title': 'Emergent Communication at Scale (exclude resnet)',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "print('Params without resnet: ', params, '. Order without resnet: ', order)\n",
    "\n",
    "params += params_resnet # effectively resnet embeddings are used as referents and resnet isn't part of the agent, but we'll add it anyway\n",
    "order = len(str(params))\n",
    "parameter_sizes.append({\n",
    "    'title': 'Emergent Communication at Scale (include resnet)',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "print('Params with resnet: ', params, '. Order with resnet: ', order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fb485-b3e9-4b87-9a29-016307c50ef0",
   "metadata": {},
   "source": [
    "## 14. Interaction history as a source of compositionality in emergent communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2d8b0af-509b-47cf-aea4-327a4a06efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rather than installing EGG, we're simply going to grab and run this bit of code from\n",
    "# https://github.com/facebookresearch/EGG/blob/main/egg/core/reinforce_wrappers.py\n",
    "\n",
    "class RnnSenderReinforce(nn.Module):\n",
    "    \"\"\"\n",
    "    Reinforce Wrapper for Sender in variable-length message game. Assumes that during the forward,\n",
    "    the wrapped agent returns the initial hidden state for a RNN cell. This cell is the unrolled by the wrapper.\n",
    "    During training, the wrapper samples from the cell, getting the output message. Evaluation-time, the sampling\n",
    "    is replaced by argmax.\n",
    "\n",
    "    >>> class Agent(nn.Module):\n",
    "    ...     def __init__(self):\n",
    "    ...         super().__init__()\n",
    "    ...         self.fc = nn.Linear(10, 3)\n",
    "    ...     def forward(self, x, _input=None, _aux_input=None):\n",
    "    ...         return self.fc(x)\n",
    "    >>> agent = Agent()\n",
    "    >>> agent = RnnSenderReinforce(agent, vocab_size=5, embed_dim=5, hidden_size=3, max_len=10, cell='lstm')\n",
    "    >>> input = torch.FloatTensor(16, 10).uniform_(-0.1, 0.1)\n",
    "    >>> message, logprob, entropy = agent(input)\n",
    "    >>> message.size()  # batch size x max_len+1\n",
    "    torch.Size([16, 11])\n",
    "    >>> (entropy[:, -1] > 0).all().item()  # EOS symbol will have 0 entropy\n",
    "    False\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        agent,\n",
    "        vocab_size,\n",
    "        embed_dim,\n",
    "        hidden_size,\n",
    "        max_len,\n",
    "        num_layers=1,\n",
    "        cell=\"rnn\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param agent: the agent to be wrapped\n",
    "        :param vocab_size: the communication vocabulary size\n",
    "        :param embed_dim: the size of the embedding used to embed the output symbols\n",
    "        :param hidden_size: the RNN cell's hidden state size\n",
    "        :param max_len: maximal length of the output messages\n",
    "        :param cell: type of the cell used (rnn, gru, lstm)\n",
    "        \"\"\"\n",
    "        super(RnnSenderReinforce, self).__init__()\n",
    "        self.agent = agent\n",
    "\n",
    "        assert max_len >= 1, \"Cannot have a max_len below 1\"\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self.hidden_to_output = nn.Linear(hidden_size, vocab_size)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.sos_embedding = nn.Parameter(torch.zeros(embed_dim))\n",
    "        self.embed_dim = embed_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_layers = num_layers\n",
    "        self.cells = None\n",
    "\n",
    "        cell = cell.lower()\n",
    "        cell_types = {\"rnn\": nn.RNNCell, \"gru\": nn.GRUCell, \"lstm\": nn.LSTMCell}\n",
    "\n",
    "        if cell not in cell_types:\n",
    "            raise ValueError(f\"Unknown RNN Cell: {cell}\")\n",
    "\n",
    "        cell_type = cell_types[cell]\n",
    "        self.cells = nn.ModuleList(\n",
    "            [\n",
    "                cell_type(input_size=embed_dim, hidden_size=hidden_size)\n",
    "                if i == 0\n",
    "                else cell_type(input_size=hidden_size, hidden_size=hidden_size)\n",
    "                for i in range(self.num_layers)\n",
    "            ]\n",
    "        )  # noqa: E502\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.normal_(self.sos_embedding, 0.0, 0.01)\n",
    "\n",
    "    def forward(self, x, aux_input=None):\n",
    "        prev_hidden = [self.agent(x, aux_input)]\n",
    "        prev_hidden.extend(\n",
    "            [torch.zeros_like(prev_hidden[0]) for _ in range(self.num_layers - 1)]\n",
    "        )\n",
    "\n",
    "        prev_c = [\n",
    "            torch.zeros_like(prev_hidden[0]) for _ in range(self.num_layers)\n",
    "        ]  # only used for LSTM\n",
    "\n",
    "        input = torch.stack([self.sos_embedding] * x.size(0))\n",
    "\n",
    "        sequence = []\n",
    "        logits = []\n",
    "        entropy = []\n",
    "\n",
    "        for step in range(self.max_len):\n",
    "            for i, layer in enumerate(self.cells):\n",
    "                if isinstance(layer, nn.LSTMCell):\n",
    "                    h_t, c_t = layer(input, (prev_hidden[i], prev_c[i]))\n",
    "                    prev_c[i] = c_t\n",
    "                else:\n",
    "                    h_t = layer(input, prev_hidden[i])\n",
    "                prev_hidden[i] = h_t\n",
    "                input = h_t\n",
    "\n",
    "            step_logits = F.log_softmax(self.hidden_to_output(h_t), dim=1)\n",
    "            distr = Categorical(logits=step_logits)\n",
    "            entropy.append(distr.entropy())\n",
    "\n",
    "            if self.training:\n",
    "                x = distr.sample()\n",
    "            else:\n",
    "                x = step_logits.argmax(dim=1)\n",
    "            logits.append(distr.log_prob(x))\n",
    "\n",
    "            input = self.embedding(x)\n",
    "            sequence.append(x)\n",
    "\n",
    "        sequence = torch.stack(sequence).permute(1, 0)\n",
    "        logits = torch.stack(logits).permute(1, 0)\n",
    "        entropy = torch.stack(entropy).permute(1, 0)\n",
    "\n",
    "        zeros = torch.zeros((sequence.size(0), 1)).to(sequence.device)\n",
    "\n",
    "        sequence = torch.cat([sequence, zeros.long()], dim=1)\n",
    "        logits = torch.cat([logits, zeros], dim=1)\n",
    "        entropy = torch.cat([entropy, zeros], dim=1)\n",
    "\n",
    "        return sequence, logits, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f9e5eb0-5e8c-42ce-ae05-d8ce5034c12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2214370, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('Interaction-history-as-a-source-of-compositionality/common')\n",
    "\n",
    "# from egg import core\n",
    "from visual_classifier import Vision\n",
    "os.chdir('../template_transfer')\n",
    "from agents import Sender\n",
    "\n",
    "cnn = Vision()\n",
    "os.chdir('..')\n",
    "speaker = RnnSenderReinforce(\n",
    "    # parameters mostly from defaults in template_transfer/train.py\n",
    "    agent=Sender(200, Vision.from_pretrained('vision_model.pth')),\n",
    "    vocab_size=10, # from paper\n",
    "    embed_dim=50,\n",
    "    hidden_size=200,\n",
    "    max_len=1,\n",
    "    cell='rnn'\n",
    ")\n",
    "\n",
    "params, order = count_parameters(torch.nn.Sequential(cnn, speaker))\n",
    "parameter_sizes.append({\n",
    "    'title': 'Interaction history as a source of compositionality in emergent communication',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93efb6de-75b8-40d5-bf21-9f5a41f5fffe",
   "metadata": {},
   "source": [
    "## 15. Emergent communication of generalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b241edf6-e1ed-4a4c-8aab-4519f0c9bba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11524635, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('emergent-generalization/code/models')\n",
    "\n",
    "from speaker import Speaker\n",
    "from vision import ResNet18\n",
    "\n",
    "vocab_size = 20 # vocab for the birds game as specified in the paper\n",
    "embedding_size = 500 # from the paper\n",
    "\n",
    "#This is based on what's in builder.py:\n",
    "speaker = Speaker(ResNet18(), nn.Embedding(vocab_size + 3, embedding_size))\n",
    "\n",
    "params, order = count_parameters(speaker)\n",
    "parameter_sizes.append({\n",
    "    'title': 'Emergent communication of generalizations',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6607ab-9903-4744-8cfa-39091d586529",
   "metadata": {},
   "source": [
    "## 16. Compositionality Through Language Transmission, using Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afc74b30-c780-4591-b664-c49809f1483b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23304, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('neural-ilm/ilm')\n",
    "\n",
    "from ilm_rnn_2018jan import AgentModel\n",
    "\n",
    "speaker = AgentModel(\n",
    "    # based on the defaults in ilm_rnn_2018jan.py\n",
    "    5,\n",
    "    10,\n",
    "    50,\n",
    "    4,\n",
    "    20\n",
    ")\n",
    "\n",
    "params, order = count_parameters(speaker)\n",
    "parameter_sizes.append({\n",
    "    'title': 'Compositionality Through Language Transmission, using Artificial Neural Networks',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac9a04a-3b78-48ff-8447-6eaf387c98e5",
   "metadata": {},
   "source": [
    "## 17. TexRel: a Green Family of Datasets for Emergent Communications on Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1499f908-735f-4393-ac9b-2429c2db9929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132293, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('texrel/ref_task/models')\n",
    "\n",
    "if \"models\" in sys.modules:\n",
    "    del sys.modules[\"models\"] # we used models before from a different repository!\n",
    " \n",
    "from sender_model import SenderModel\n",
    "from image_seq_embedders import PrototypicalSender\n",
    "from decoders_differentiable import RNNDecoder\n",
    "from pre_conv import StridedConv\n",
    "\n",
    "speaker = SenderModel(\n",
    "    # Arguments here based on defaults in ref_task/params_groups.py\n",
    "    StridedConv(\n",
    "        3, # Implied to be equal to grid_planes (see below) in ref_task/models/conv_models.py\n",
    "        64, # Implied to be 64 by default in ref_task/models/conv_models.py\n",
    "        0.2, # In ref_task/params_groups.py as --preconv-dropout\n",
    "        4, # In ref_task/params_groups.py as --preconv-stride\n",
    "        True # In ref_task/params_groups.py as --preconv-relu\n",
    "    ),\n",
    "    PrototypicalSender(\n",
    "        128, # In ref_task/params_groups.py as --embedding-size\n",
    "        0, # In ref_task/params_groups.py as --dropout\n",
    "        (16, 16), # In ref_task/params_groups.py as --cnn-sizes, wants to be passed as an iterable here\n",
    "        5 * 5, # In texrel/create_colletion.py as --grid-size, default 5, and needs to be multiplied by the size of the textures in the texrel images as shown in texrel/dataset_runtine.py, which (looking at the images in the paper) is about 5 pixels\n",
    "        3, # In texrel/dataset_runtine.py as self.meta.grid_planes\n",
    "        None, # In ref_task/params_groups.py as --cnn-max-pooling-size\n",
    "        True # In ref_task/params_groups.py as --cnn-batch-norm\n",
    "    ),\n",
    "    RNNDecoder(\n",
    "        128, # In ref_task/params_groups.py as --embedding-size\n",
    "        10, # In ref_task/params_groups.py as --utt-len\n",
    "        21 # In ref_task/params_groups.py as --vocab-size\n",
    "    ),\n",
    "    True\n",
    ")\n",
    "\n",
    "params, order = count_parameters(speaker)\n",
    "parameter_sizes.append({\n",
    "    'title': 'TexRel: a Green Family of Datasets for Emergent Communications on Relations',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a398d-f4c0-471c-986e-97982830fde5",
   "metadata": {},
   "source": [
    "## 18. Disentangling Categorization in Multi-agent Emergent Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a18ce39-6012-4b25-858c-593e7bad7098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers [3, 4, 6, 3] select 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24379280, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('disentangling_categorization/research_pool/config_archive/SEMIOSIS/111121-065556')\n",
    "\n",
    "import json\n",
    "with open('0_seed-0.json') as config: # This config uses a Resnet-50 as CNN\n",
    "  state = json.loads(config.read())\n",
    "state['device'] = 'cuda'\n",
    "\n",
    "os.chdir(original_working_directory)\n",
    "os.chdir('disentangling_categorization')\n",
    "\n",
    "import os\n",
    "os.environ[\"DATA_ROOT\"] = \"data\"\n",
    "os.environ[\"SAVE_ROOT\"] = \"SAVE_ROOT\"\n",
    "os.environ[\"DISENT_ROOT\"] = \".\"\n",
    "\n",
    "import model_builder\n",
    "\n",
    "speaker = model_builder.build_complete_sender(state)\n",
    "\n",
    "params, order = count_parameters(torch.nn.Sequential(speaker[0], speaker[1]))\n",
    "parameter_sizes.append({\n",
    "    'title': 'Disentangling Categorization in Multi-agent Emergent Communication',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c43e4ba-52d6-4fd9-8c83-e362c48c4faa",
   "metadata": {},
   "source": [
    "## 19. Emergence of hierarchical reference systems in multi-agent communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6eccf555-743b-44b5-8be9-df89600271e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141056, 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('hierarchical_reference_game')\n",
    "\n",
    "from archs import Sender\n",
    "\n",
    "# based on what's in train.py\n",
    "sender = Sender(256, 32, 4)\n",
    "\n",
    "params, order = count_parameters(sender)\n",
    "parameter_sizes.append({\n",
    "    'title': 'Emergence of hierarchical reference systems in multi-agent communication',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e1d41-c31a-426e-8ea8-a1870b94ab52",
   "metadata": {},
   "source": [
    "## 20. Emergent Communication: Generalization and Overfitting in Lewis Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9a3852c-c293-4a94-9985-f910f8f43fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params without resnet:  135306 . Order without resnet:  6\n",
      "Params with resnet:  25692338 . Order with resnet:  8\n"
     ]
    }
   ],
   "source": [
    "os.chdir(original_working_directory)\n",
    "os.chdir('Population/default_experiment/default_json')\n",
    "\n",
    "import json\n",
    "with open('agents.json') as config:\n",
    "  sender_params = json.loads(config.read())['sender_default_reco']['sender_params']\n",
    "#state['device'] = 'cuda'\n",
    "\n",
    "os.chdir(original_working_directory)\n",
    "os.chdir('Population/src/core')\n",
    "\n",
    "# trainers.py indicates that the parameters of the sender should be considered to be\n",
    "#   agent.sender.parameters() + agent.object_encoder.parameters()\n",
    "\n",
    "from senders import build_sender\n",
    "\n",
    "# sender_params = {\n",
    "#     # based on \n",
    "#     \"sender_type\": \"recurrent\"\n",
    "#     \"sender_cell\": \"gru\"\n",
    "#     \"sender_type\": \"recurrent\"\n",
    "# }\n",
    "game_params = {\n",
    "    \"objects\": {\"object_type\": \"dummy\"},\n",
    "    \"channel\": {\n",
    "        \"voc_size\": 10, # From default_json/onehotcompositionality_game.json\n",
    "        \"max_len\": 10, # From default_json/onehotcompositionality_game.json\n",
    "    }\n",
    "}\n",
    "sender = build_sender(sender_params, game_params)\n",
    "\n",
    "params, order = count_parameters(sender)\n",
    "\n",
    "# This paper uses a resnet to preprocess images to make referents, so it's not\n",
    "#   clear whether we should include the resnet as part of the speaker agent\n",
    "#   size. We'll take two measurements, one for each case\n",
    "\n",
    "# See also `13. Emergent Communication at Scale` above, who take the same approach\n",
    "\n",
    "order = len(str(params))\n",
    "parameter_sizes.append({\n",
    "    'title': 'Emergent Communication: Generalization and Overfitting in Lewis Games (exclude resnet)',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "print('Params without resnet: ', params, '. Order without resnet: ', order)\n",
    "\n",
    "params += params_resnet # effectively resnet embeddings are used as referents and resnet isn't part of the agent, but we'll add it anyway\n",
    "order = len(str(params))\n",
    "parameter_sizes.append({\n",
    "    'title': 'Emergent Communication: Generalization and Overfitting in Lewis Games (include resnet)',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "print('Params with resnet: ', params, '. Order with resnet: ', order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07e9035-cc43-450b-a8c5-ab446f34b4f8",
   "metadata": {},
   "source": [
    "## 21. On the Correspondence between Compositionality and Imitation in Emergent Neural Communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fff044a-28df-4aad-af7a-2759fd3296e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106880, 6)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The paper (https://aclanthology.org/2023.findings-acl.787.pdf) \n",
    "says \"The Sender is a single-layer GRU (Cho et al., 2014)\n",
    "containing a fully-connected (FC) layer that maps the input\n",
    "x to its first hidden state (dim=128).\"\n",
    "And also says\n",
    "\"Each input x denotes an object in an “attribute-\n",
    "value world\", where the object has n_{att} attributes,\n",
    "and each attribute takes n_{val} possible values. We\n",
    "represent x by a concatenation of n_{att} one-hot vec-\n",
    "tors, each of dimension {n_val}.\n",
    "...\n",
    "We set n_{att} = 6, n_{val} = 10\"\n",
    "'''\n",
    "class ImitNet(nn.Module):\n",
    "\n",
    "    # network structure\n",
    "    def __init__(self):\n",
    "        super(ImitNet, self).__init__()\n",
    "        self.fc = nn.Linear(6 * 10, 128)\n",
    "        self.gru = nn.GRU(128, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        One forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: input\n",
    "        '''\n",
    "       \n",
    "        return self.gru(self.fc(x))\n",
    "\n",
    "params, order = count_parameters(ImitNet())\n",
    "parameter_sizes.append({\n",
    "    'title': 'On the Correspondence between Compositionality and Imitation in Emergent Neural Communication',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768c21b7-5e96-4547-bdd2-7b2aa877169f",
   "metadata": {},
   "source": [
    "## 22. Compositionality with Variation Reliably Emerges in Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b959397b-70eb-40f6-8a08-598753cb4b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17810, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The paper says\n",
    "\"\"\"\n",
    "The overall architecture used is intentionally similar to Chaabouni et al. (2020); Resnick et al. (2020) and\n",
    "Guo et al. (2021) to allow comparison of results. The sender network is comprised of an embedding layer,\n",
    "linear layer, and a GRU (Cho et al., 2014\n",
    "\"\"\"\n",
    "\n",
    "# Here is the same model we made to mock up Chaabouni (2020),\n",
    "# with parameters changed according to configs/iclr_2023.jsonnet and the paper\n",
    "class VariationNet(nn.Module):\n",
    "\n",
    "    # network structure\n",
    "    def __init__(self):\n",
    "        super(VariationNet, self).__init__()\n",
    "        self.vocab = 26 # 'signal_alphabet_size' from configs/iclr_2023.jsonnet\n",
    "        self.embedding_size = 52 # 'embedding_size' from configs/iclr_2023.jsonnet\n",
    "        self.input_size = 75 # sum of 'n_atoms_per_role' from configs/iclr_2023.jsonnet based on 1-hot vector input\n",
    "        self.fc1   = nn.Linear(self.input_size, self.embedding_size)\n",
    "        self.gru   = nn.GRU(self.vocab, self.embedding_size)\n",
    "        self.fc2   = nn.Linear(self.embedding_size, self.vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        One forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: input\n",
    "        '''\n",
    "        hidden = self.fc1(x)\n",
    "        out, hidden = self.gru(x, hidden)\n",
    "        return self.fc2(out)\n",
    "\n",
    "\n",
    "params, order = count_parameters(VariationNet())\n",
    "parameter_sizes.append({\n",
    "    'title': 'Compositionality with Variation Reliably Emerges in Neural Networks',\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6255da8c-c416-4a46-ab6c-9fc681cb2599",
   "metadata": {},
   "source": [
    "## 23. On the Word Boundaries of Emergent Languages Based on Harris's Articulation Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c564fd43-d62f-455c-9139-f23683bb8527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153600, 7)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The paper says\n",
    "# \"We have to define environments, agent architectures, and optimization methods for language emer-\n",
    "# gence simulations. This paper adopts the framework of Chaabouni et al. (2020). ...\n",
    "# We follow Chaabouni et al. (2020) as well for the architecture and optimization method.\"\n",
    "\n",
    "# Same game and architecture as Chaabouni, so inherit param size results from that paper:\n",
    "inherits_from = 'Compositionality and Generalization in Emergent Languages'\n",
    "previous_calculation = [p for p in parameter_sizes if p['title'] == inherits_from][0]\n",
    "params, order = previous_calculation['params'], previous_calculation['order']\n",
    "\n",
    "parameter_sizes.append({\n",
    "    'title': \"On the Word Boundaries of Emergent Languages Based on Harris's Articulation Scheme\",\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "params, order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d5a39-901c-427e-a587-e22a46fec3d8",
   "metadata": {},
   "source": [
    "## 24. Lewis's Signaling Game as beta-VAE For Natural Word Lengths and Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "324c8637-1048-419d-b751-ef2cee667cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153600, 7)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same game and architecture as Chaabouni, and \"On the word boundaries\"\n",
    "# so inherit param size results from Chaabouni. Additional language model\n",
    "# is conceptualised to be part of the receiver.\n",
    "\n",
    "inherits_from = 'Compositionality and Generalization in Emergent Languages'\n",
    "previous_calculation = [p for p in parameter_sizes if p['title'] == inherits_from][0]\n",
    "params, order = previous_calculation['params'], previous_calculation['order']\n",
    "\n",
    "parameter_sizes.append({\n",
    "    'title': \"Lewis's Signaling Game as beta-VAE For Natural Word Lengths and Segments\",\n",
    "    'params': params,\n",
    "    'order': order\n",
    "})\n",
    "\n",
    "params, order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69599ebb-ea51-4d06-ad8e-2e3a7932c600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>params</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natural language does not emerge ’naturally’ i...</td>\n",
       "      <td>29885</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emergence of Grounded Compositional Language i...</td>\n",
       "      <td>1870105</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Emergence of Communication in an Interactive W...</td>\n",
       "      <td>45253</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compositional Obverter Communication Learning ...</td>\n",
       "      <td>64676</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emergence of Compositional Language with Deep ...</td>\n",
       "      <td>107956</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Emergence of Compositional Languages for N...</td>\n",
       "      <td>6264858</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ease-of-Teaching and Language Structure from E...</td>\n",
       "      <td>46108</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Compositional Languages Emerge in a Neural Ite...</td>\n",
       "      <td>73872</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Compositionality and Generalization in Emergen...</td>\n",
       "      <td>1153600</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Co-evolution of language and agents in referen...</td>\n",
       "      <td>1696909</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Inductive Bias and Language Expressivity in Em...</td>\n",
       "      <td>443584</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Capacity, Bandwidth, and Compositionality in E...</td>\n",
       "      <td>670982</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Emergent Communication at Scale (exclude resnet)</td>\n",
       "      <td>1328870</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Emergent Communication at Scale (include resnet)</td>\n",
       "      <td>26885902</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Interaction history as a source of composition...</td>\n",
       "      <td>2214370</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Emergent communication of generalizations</td>\n",
       "      <td>11524635</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Compositionality Through Language Transmission...</td>\n",
       "      <td>23304</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TexRel: a Green Family of Datasets for Emergen...</td>\n",
       "      <td>132293</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Disentangling Categorization in Multi-agent Em...</td>\n",
       "      <td>24379280</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Emergence of hierarchical reference systems in...</td>\n",
       "      <td>141056</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Emergent Communication: Generalization and Ove...</td>\n",
       "      <td>135306</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Emergent Communication: Generalization and Ove...</td>\n",
       "      <td>25692338</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>On the Correspondence between Compositionality...</td>\n",
       "      <td>106880</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Compositionality with Variation Reliably Emerg...</td>\n",
       "      <td>17810</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>On the Word Boundaries of Emergent Languages B...</td>\n",
       "      <td>1153600</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lewis's Signaling Game as beta-VAE For Natural...</td>\n",
       "      <td>1153600</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title    params  order\n",
       "0   Natural language does not emerge ’naturally’ i...     29885      5\n",
       "1   Emergence of Grounded Compositional Language i...   1870105      7\n",
       "2   Emergence of Communication in an Interactive W...     45253      5\n",
       "3   Compositional Obverter Communication Learning ...     64676      5\n",
       "4   Emergence of Compositional Language with Deep ...    107956      6\n",
       "5   The Emergence of Compositional Languages for N...   6264858      7\n",
       "6   Ease-of-Teaching and Language Structure from E...     46108      5\n",
       "7   Compositional Languages Emerge in a Neural Ite...     73872      5\n",
       "8   Compositionality and Generalization in Emergen...   1153600      7\n",
       "9   Co-evolution of language and agents in referen...   1696909      7\n",
       "10  Inductive Bias and Language Expressivity in Em...    443584      6\n",
       "11  Capacity, Bandwidth, and Compositionality in E...    670982      6\n",
       "12   Emergent Communication at Scale (exclude resnet)   1328870      7\n",
       "13   Emergent Communication at Scale (include resnet)  26885902      8\n",
       "14  Interaction history as a source of composition...   2214370      7\n",
       "15          Emergent communication of generalizations  11524635      8\n",
       "16  Compositionality Through Language Transmission...     23304      5\n",
       "17  TexRel: a Green Family of Datasets for Emergen...    132293      6\n",
       "18  Disentangling Categorization in Multi-agent Em...  24379280      8\n",
       "19  Emergence of hierarchical reference systems in...    141056      6\n",
       "20  Emergent Communication: Generalization and Ove...    135306      6\n",
       "21  Emergent Communication: Generalization and Ove...  25692338      8\n",
       "22  On the Correspondence between Compositionality...    106880      6\n",
       "23  Compositionality with Variation Reliably Emerg...     17810      5\n",
       "24  On the Word Boundaries of Emergent Languages B...   1153600      7\n",
       "25  Lewis's Signaling Game as beta-VAE For Natural...   1153600      7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "os.chdir(original_working_directory)\n",
    "\n",
    "parameter_size_df = pd.DataFrame(parameter_sizes)\n",
    "\n",
    "parameter_size_df.to_csv('output.csv', encoding='utf-8', index=False)\n",
    "\n",
    "parameter_size_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6de38d3-acf2-4001-8d51-af70f28d4565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>params</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Emergence of Compositional Languages for N...</td>\n",
       "      <td>6264858</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Emergent Communication at Scale (include resnet)</td>\n",
       "      <td>26885902</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Emergent communication of generalizations</td>\n",
       "      <td>11524635</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Disentangling Categorization in Multi-agent Em...</td>\n",
       "      <td>24379280</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Emergent Communication: Generalization and Ove...</td>\n",
       "      <td>25692338</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title    params  order\n",
       "5   The Emergence of Compositional Languages for N...   6264858      7\n",
       "13   Emergent Communication at Scale (include resnet)  26885902      8\n",
       "15          Emergent communication of generalizations  11524635      8\n",
       "18  Disentangling Categorization in Multi-agent Em...  24379280      8\n",
       "21  Emergent Communication: Generalization and Ove...  25692338      8"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many studies equal or exceed the ~6 million parameters of MobileViT?\n",
    "\n",
    "parameter_size_df[parameter_size_df['params'] > 6E6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8044686-6db5-481a-904a-1c85d9c628ba",
   "metadata": {},
   "source": [
    "## Finish by fixing any environment weirdness that might have occurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d217ece1-947c-427c-9c1c-98b27f222f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      " - nvidia\n",
      " - pytorch\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y --file conda_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4be2cabe-1510-4cd6-b6cd-6997551532c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet -r pip_requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
