{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "how does distribution of hyp values differ by symbol?\n",
    "\n",
    "in this one, we'll graph the distributions of the argmaxes, rather than the raw values\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "def run(filename):\n",
    "    shutil.copyfile(f'../{filename}', '/tmp/foo.h5')\n",
    "    f = h5py.File('/tmp/foo.h5', 'r')\n",
    "\n",
    "    hypotheses_train = torch.from_numpy(f['hypotheses_train'][:])\n",
    "    dsrefs_train = torch.from_numpy(f['dsrefs_train'][:].astype(np.uint8)).long()\n",
    "    resdicts = f['resdicts']\n",
    "    \n",
    "    meta = json.loads(f['meta'][0])\n",
    "    ref = meta['ref']\n",
    "\n",
    "    U_pred = hypotheses_train.size(0)\n",
    "    V = hypotheses_train.size(2)\n",
    "    N = dsrefs_train.size(0)\n",
    "\n",
    "    batch_size = 128\n",
    "\n",
    "    sample_render_ids = 4\n",
    "    num_render_ids = len(resdicts)\n",
    "\n",
    "    render_start_id = 0\n",
    "    num_samples = num_render_ids // sample_render_ids\n",
    "    \n",
    "    ids_to_render = []\n",
    "    for i in range(num_samples):\n",
    "        ids_to_render.append(num_render_ids - sample_render_ids * (num_samples - i))\n",
    "\n",
    "    results = torch.zeros(num_samples, U_pred, dtype=torch.float32)\n",
    "    episodes = []\n",
    "    for i, render_id in enumerate(ids_to_render):\n",
    "        resdict = json.loads(resdicts[render_id])\n",
    "        episode = resdict['episode']\n",
    "        episodes.append(episode)\n",
    "        n_start = render_id * batch_size\n",
    "        n_end = (render_id + sample_render_ids) * batch_size\n",
    "        _hypotheses_train = hypotheses_train[:, n_start:n_end]\n",
    "\n",
    "        for u in range(U_pred):\n",
    "            _preds = _hypotheses_train[u, :].max(dim=-1)[1]\n",
    "            total_count = _preds.size(0)\n",
    "            non_zero_symbol_count = (_preds != 0).long().sum().item()\n",
    "            results[i, u] = non_zero_symbol_count / total_count\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    for u in range(U_pred):\n",
    "        plt.plot(episodes, results[:, u].numpy(), label=f'utterance pos {u}')\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlabel('episode')\n",
    "    plt.ylabel('proportion of non-zero symbol chosen')\n",
    "    plt.title(f'{ref} proportion of non-zero symbol chosen, per position')\n",
    "    plt.show()\n",
    "\n",
    "    f.close()\n",
    "\n",
    "filenames = \"\"\"\n",
    "../hists/hypprop_eec59_hughtok1_20180929_150429.h5\n",
    "../hists/hypprop_eec60_hughtok2_20180929_150511.h5\n",
    "../hists/hypprop_eec61_hughtok33_20180929_150540.h5\n",
    "../hists/hypprop_eec64_hughtok4_20180930_135141.h5\n",
    "../hists/hypprop_eec65_hughtok5_20180930_135510.h5\n",
    "../hists/hypprop_eec66_hughtok6_20180930_141031.h5\n",
    "../hists/hypprop_eec67_hughtok7_20180930_141448.h5\n",
    "../hists/hypprop_eec68_hughtok8_20180930_141821.h5\n",
    "\"\"\"\n",
    "\n",
    "filenames = filenames.split('\\n')\n",
    "filenames = [f.replace('../', '') for f in filenames if f != '']\n",
    "# filenames = [filenames[-1]]\n",
    "\n",
    "for filename in filenames:\n",
    "    run(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
