{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics.cluster\n",
    "\n",
    "import torch\n",
    "\n",
    "# filename = 'hists/hypprop_with_predictor_eeb99_hughtok1_20180921_191657.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb100_hughtok2_20180921_193244.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb101_hughtok3_20180921_193516.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb102_hughtok4_20180921_193310.h5'\n",
    "\n",
    "# filename = 'hists/hypprop_with_predictor_eeb103_hughtok1_20180921_212947.h5'\n",
    "\n",
    "# filename = 'hists/hypprop_with_predictor_eeb105_hughtok5_20180921_230949.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb106_hughtok6_20180921_231010.h5'\n",
    "\n",
    "# filename = 'hists/hypprop_with_predictor_eeb107_hughtok2_20180922_013551.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb108_hughtok1_20180922_170013.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb109_hughtok2_20180922_184537.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb113_hughtok6_20180922_211153.h5'\n",
    "\n",
    "# filename = 'hists/hypprop_with_predictor_eeb115_hughtok1_20180923_173818.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb116_hughtok2_20180923_175444.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb117_hughtok3_20180923_175444.h5'\n",
    "\n",
    "# filename = 'hists/hypprop_with_predictor_eeb132_hughtok3_20180925_014550.h5'\n",
    "\n",
    "# filename = 'hists/hypprop_with_predictor_eeb135_hughtok6_20180925_082442.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eec16_hughtok1_20180927_011347.h5'\n",
    "filename = 'hists/hypprop_eec79_hughtok5_20181006_135449.h5'\n",
    "\n",
    "def run(filename):\n",
    "    shutil.copyfile(f'../{filename}', '/tmp/foo.h5')\n",
    "    f = h5py.File('/tmp/foo.h5', 'r')\n",
    "\n",
    "    hypotheses_train = torch.from_numpy(f['hypotheses_train'][:])\n",
    "    hypotheses_gnd_train = torch.from_numpy(f['gnd_hypotheses_train'][:].astype(np.uint8)).long()\n",
    "    dsrefs_train = torch.from_numpy(f['dsrefs_train'][:].astype(np.uint8)).long()\n",
    "    resdicts = f['resdicts']\n",
    "    \n",
    "    meta = json.loads(f['meta'][0])\n",
    "    ref = meta['ref']\n",
    "\n",
    "    U_gnd = hypotheses_gnd_train.size(0)\n",
    "    U_pred = hypotheses_train.size(0)\n",
    "\n",
    "    N = dsrefs_train.size(0)\n",
    "\n",
    "    render_start_id = 0\n",
    "    render_end_id_excl = len(resdicts)\n",
    "\n",
    "    batch_size = 128\n",
    "\n",
    "    print('hypotheses_train.size()', hypotheses_train.size())\n",
    "    _hypotheses_train = hypotheses_train[:, -32:].contiguous()\n",
    "    _hypotheses_gnd_train = hypotheses_gnd_train[:, -4:].contiguous()\n",
    "    \n",
    "    _N = _hypotheses_train.view(-1).size(0)\n",
    "    print('_N', _N)\n",
    "    plt.scatter(np.arange(_N), _hypotheses_train.view(-1).numpy())\n",
    "    plt.title(ref)\n",
    "    plt.show()\n",
    "    \n",
    "    for u in range(U_pred):\n",
    "        _h = _hypotheses_train[u].contiguous().view(-1)\n",
    "        _N = _h.size(0)\n",
    "        plt.scatter(np.arange(_N) + _N * u, _h.numpy(), s=20)\n",
    "    plt.title(ref)\n",
    "    plt.show()\n",
    "\n",
    "    for u in range(U_pred):\n",
    "        _h = _hypotheses_train[u].contiguous().view(-1)\n",
    "        _N = _h.size(0)\n",
    "        plt.scatter(np.arange(_N), _h.numpy(), s=20, label=str(u))\n",
    "    plt.legend()\n",
    "    plt.title(ref)\n",
    "    plt.show()\n",
    "\n",
    "    for u in range(U_pred):\n",
    "        _h = _hypotheses_train[u].contiguous().view(-1)\n",
    "        _N = _h.size(0)\n",
    "        plt.scatter(np.arange(_N), _h.numpy(), s=20)\n",
    "        plt.title(ref)\n",
    "        plt.show()\n",
    "\n",
    "#     for u_gnd in range(U_gnd):\n",
    "    V = _hypotheses_train.size(-1)\n",
    "    print('V', V)\n",
    "    for gnd_symbol in range(V):\n",
    "#         print('_hypotheses_gnd_train[0]', _hypotheses_gnd_train[0])\n",
    "        _idxes = (_hypotheses_gnd_train[0] == gnd_symbol).view(-1).nonzero().view(-1).long()\n",
    "#         print('_idxes', _idxes)\n",
    "        if len(_idxes.size()) != 1 or _idxes.size(0) == 0:\n",
    "            continue\n",
    "        _h = _hypotheses_train[:, _idxes]\n",
    "        print('gnd_symbol', gnd_symbol)\n",
    "        for u in range(U_pred):\n",
    "            _hh = _h[u].contiguous().view(-1)\n",
    "            _N = _hh.size(0)\n",
    "            plt.scatter(np.arange(_N) + _N * u, _hh.numpy(), s=20)\n",
    "        plt.show()\n",
    "\n",
    "#         plt.figure(figsize=(10.0 * U_gnd, 0.15 * num_renders))\n",
    "#         plt.cla()\n",
    "#         for u_gnd in range(U_gnd):\n",
    "#             plt.subplot(1, 5, u_gnd + 1)\n",
    "#             ami = amis[:, :, u_gnd]\n",
    "# #             print('u_gnd', u_gnd, 'ami.size()', ami.size())\n",
    "#             plt.imshow(ami.numpy())\n",
    "#         plt.show()\n",
    "    f.close()\n",
    "\n",
    "run(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
