{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at utterances, by finding the marginal in onehot space, for each meaning type/value combination, then argmaxing it to find some kind of. Well... let's find the entropy of each utterance position, for each type/value combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from os import path\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    print('appending .. to path')\n",
    "    sys.path.append('..')\n",
    "import ulfs\n",
    "from ulfs.utils import expand, die\n",
    "from mll import e2e_fixpoint\n",
    "from mll import run_mem_recv, run_mem_send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = '../models/mll236_230k.dat'\n",
    "# model_path = '../tmp/e2e_fixpoint_mll241_hughtok2_20190106_195828.dat'\n",
    "model_path = '../tmp/e2e_fixpoint_mll244_hughtok4_20190107_001304.dat'\n",
    "\n",
    "with open(model_path, 'rb') as f:\n",
    "    model_dat = torch.load(f)\n",
    "print(model_dat.keys())\n",
    "episode = model_dat['episode']\n",
    "print('episode', episode)\n",
    "from ulfs.params import Params\n",
    "params = model_dat['params']\n",
    "print('params', params)\n",
    "\n",
    "default_params = e2e_fixpoint.default_params\n",
    "for k, v in default_params.items():\n",
    "    if k not in params:\n",
    "        setattr(params, k, v)\n",
    "\n",
    "sender_agent = run_mem_send.Agent(params)\n",
    "print('sender_agent', sender_agent)\n",
    "sender_model = sender_agent.model\n",
    "print('sender_model', sender_model)\n",
    "sender_model.load_state_dict(model_dat['sender_model_state'])\n",
    "print('sender_model', sender_model)\n",
    "\n",
    "p = params\n",
    "tot_examples = int(math.pow(p.meanings_per_type, p.num_meaning_types))\n",
    "print('tot_examples', tot_examples)\n",
    "meanings_ints = torch.from_numpy(np.arange(tot_examples))\n",
    "# meanings = torch.zeros(*([p.meanings_per_type] * p.num_meaning_types))\n",
    "meanings = torch.zeros(tot_examples, p.num_meaning_types, dtype=torch.int64)\n",
    "print('meanings.size()', meanings.size())\n",
    "for t in range(p.num_meaning_types):\n",
    "    meanings[:, p.num_meaning_types - t - 1] = meanings_ints % p.meanings_per_type\n",
    "    meanings_ints = meanings_ints // p.meanings_per_type\n",
    "# print('meanings[:110]', meanings[:110])\n",
    "\n",
    "# sample_idxes = torch.from_numpy(np.random.choice(tot_examples, 1000, replace=False))\n",
    "# # meanings = meanings[:1000]\n",
    "# meanings = meanings[sample_idxes]\n",
    "# print('meanings.size()', meanings.size())\n",
    "\n",
    "utt_logits = sender_model(meanings)\n",
    "# print('utt_logits', utt_logits)\n",
    "print('utt_logits.size()', utt_logits.size())\n",
    "_, utt_preds = utt_logits.max(dim=-1)\n",
    "print('utt_preds.size()', utt_preds.size())\n",
    "# for n in range(110):\n",
    "#     print(utt_preds[:, n])\n",
    "# target_meaning = []\n",
    "# print('utt_preds[:, :1000]', utt_preds[:, :1000])\n",
    "target_meaning_type = 0\n",
    "target_meaning_value = 0\n",
    "target_meaning_mask = meanings[:, target_meaning_type] == target_meaning_value\n",
    "target_meaning_idxes = target_meaning_mask.nonzero().view(-1).long()\n",
    "# print('target_meaning_idxes', target_meaning_idxes)\n",
    "print('target_meaning_idxes.size()', target_meaning_idxes.size())\n",
    "# for i, v in enumerate(target_meaning_idxes.tolist()):\n",
    "#     print(''.join([str(v) for v in utt_preds[:, v].tolist()]))\n",
    "# print('utt_preds[:, target_meaning_idxes]', utt_preds[:, target_meaning_idxes])\n",
    "\n",
    "utt_len = utt_preds.size(0)\n",
    "vocab_size = params.vocab_size\n",
    "print('utt_len', utt_len, 'vocab_size', vocab_size)\n",
    "N = utt_preds.size(1)\n",
    "print('N', N)\n",
    "entropies = []\n",
    "for t in range(utt_len):\n",
    "    entropy = 0\n",
    "    for i in range(vocab_size):\n",
    "        p_i = (utt_preds[t] == i).float().sum().item() / N\n",
    "        if p_i > 0:\n",
    "            entropy -= p_i * math.log(p_i)\n",
    "    entropies.append(entropy)\n",
    "print(' '.join(['%.2f' % e for e in entropies]))\n",
    "#     print(t, '%.3f' % entropy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
