{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "marginalize over the datasets, and the ground truth positions\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics.cluster\n",
    "\n",
    "import torch\n",
    "\n",
    "def create_ami_matrix(gnd, pred):\n",
    "    \"\"\"\n",
    "    assumptions:\n",
    "    - gnd and pred are 2d matrices\n",
    "    - gnd is [U_gnd][N]\n",
    "    - pred is [U_pred][N]\n",
    "    \"\"\"\n",
    "    U_gnd = gnd.size(0)\n",
    "    U_pred = pred.size(0)\n",
    "\n",
    "    ami_matrix = torch.zeros(U_pred, U_gnd)\n",
    "    for i in range(U_pred):\n",
    "        for j in range(U_gnd):\n",
    "            AMI = sklearn.metrics.cluster.adjusted_mutual_info_score(\n",
    "                labels_true=gnd[j].numpy(),\n",
    "                labels_pred=pred[i].numpy()\n",
    "            )\n",
    "            ami_matrix[i, j] = AMI\n",
    "    return ami_matrix\n",
    "\n",
    "def run(filename):\n",
    "    shutil.copyfile(f'../{filename}', '/tmp/foo.h5')\n",
    "    f = h5py.File('/tmp/foo.h5', 'r')\n",
    "\n",
    "    hypotheses_train = torch.from_numpy(f['hypotheses_train'][:])\n",
    "    hypotheses_gnd_train = torch.from_numpy(f['gnd_hypotheses_train'][:].astype(np.uint8)).long()\n",
    "    dsrefs_train = torch.from_numpy(f['dsrefs_train'][:].astype(np.uint8)).long()\n",
    "    resdicts = f['resdicts']\n",
    "\n",
    "    meta = json.loads(f['meta'][0])\n",
    "    ref = meta['ref']\n",
    "    print(ref)\n",
    "    dsrefs = meta['ds_refs']\n",
    "    \n",
    "    U_gnd = hypotheses_gnd_train.size(0)\n",
    "    U_pred = hypotheses_train.size(0)\n",
    "\n",
    "    N = dsrefs_train.size(0)\n",
    "\n",
    "    render_start_id = 0\n",
    "    render_end_id_excl = len(resdicts)\n",
    "    if render_end_id_excl > 32:\n",
    "        render_start_id = render_end_id_excl - 32\n",
    "\n",
    "    batch_size = 128\n",
    "\n",
    "    num_dsrefs = dsrefs_train.max().item() + 1\n",
    "    for dsref in range(num_dsrefs):\n",
    "        num_renders = render_end_id_excl - render_start_id\n",
    "        amis = torch.zeros((num_renders, U_pred, U_gnd), dtype=torch.float32)\n",
    "        for render_id in range(render_start_id, render_end_id_excl):\n",
    "            b_start = render_id * batch_size\n",
    "            b_end = b_start + batch_size\n",
    "            _hypotheses_train = hypotheses_train[:, b_start:b_end]\n",
    "            _hypotheses_gnd_train = hypotheses_gnd_train[:, b_start:b_end]\n",
    "            _dsrefs_train = dsrefs_train[b_start:b_end]\n",
    "\n",
    "            dsref_idxes = (_dsrefs_train == dsref).view(-1).nonzero().view(-1).long()\n",
    "            _hypotheses_train = _hypotheses_train[:, dsref_idxes]\n",
    "            _hypotheses_gnd_train = _hypotheses_gnd_train[:, dsref_idxes]\n",
    "            \n",
    "            _, _pred = _hypotheses_train.max(dim=-1)\n",
    "            ami_matrix = create_ami_matrix(\n",
    "                gnd=_hypotheses_gnd_train,\n",
    "                pred=_pred\n",
    "            )\n",
    "            amis[render_id - render_start_id] = ami_matrix\n",
    "\n",
    "        resdict_start = json.loads(resdicts[render_start_id])\n",
    "        episode_start = resdict_start['episode']\n",
    "        resdict_final = json.loads(resdicts[-1])\n",
    "        episode_final = resdict_final['episode']\n",
    "\n",
    "        gnd_utt_len = 1\n",
    "        if 'things' in dsrefs[dsref]:\n",
    "            gnd_utt_len = 2\n",
    "        elif 'rels' in dsrefs[dsref]:\n",
    "            gnd_utt_len = 5\n",
    "        for u_gnd in range(gnd_utt_len):\n",
    "            ami = amis[:, :, u_gnd]\n",
    "\n",
    "    plt.figure(figsize=(30, 0.5))\n",
    "    plt.cla()\n",
    "    plt.imshow(\n",
    "        ami.transpose(0, 1).numpy(),\n",
    "        extent=[episode_start, episode_final, 0, U_pred],\n",
    "        interpolation='none',\n",
    "        vmin=0,\n",
    "        vmax=1\n",
    "    )\n",
    "    plt.title(\n",
    "        f'{ref} episodes={episode_final} dsref={dsrefs[dsref]} u_gnd={u_gnd}'\n",
    "        f' min={ami.min().item():.3f} max={ami.max().item():.3f}')\n",
    "    plt.show()\n",
    "    f.close()\n",
    "\n",
    "filenames = [\n",
    "    'hists/hypprop_with_predictor_eeb99_hughtok1_20180921_191657.h5',\n",
    "]\n",
    "\n",
    "filenames = \"\"\"\n",
    "../hists/hypprop_eec59_hughtok1_20180929_150429.h5\n",
    "../hists/hypprop_eec60_hughtok2_20180929_150511.h5\n",
    "../hists/hypprop_eec61_hughtok33_20180929_150540.h5\n",
    "\"\"\"\n",
    "\n",
    "filenames = filenames.split('\\n')\n",
    "filenames = [f.replace('../', '') for f in filenames if f != '']\n",
    "\n",
    "for filename in filenames:\n",
    "    run(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
