{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# a lot of this is hack and pasted from jup_plot_logs\n",
    "# but prefer to hack it here, than fill jup_plot_logs with random specific stuff\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math, glob, json, os, subprocess, time, datetime, sys, importlib\n",
    "from os import path\n",
    "from os.path import join\n",
    "from collections import defaultdict, OrderedDict\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "\n",
    "import ulfs\n",
    "from ulfs.params import Params\n",
    "from ulfs import graphing, graphing_common, graphing_indexes\n",
    "importlib.reload(ulfs.graphing)\n",
    "importlib.reload(ulfs.graphing_common)\n",
    "importlib.reload(ulfs.graphing_indexes)\n",
    "\n",
    "log_dir = '../logs'\n",
    "\n",
    "import glob\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "script = 'e2e_fixpoint'\n",
    "refs = ['mll310']\n",
    "# refs = ['mll186b', 'mll187', 'mll188', 'mll232', 'mll233']\n",
    "value_keys = ['e2e_loss', 'e2e_acc', 'send_acc', 'recv_acc']\n",
    "# filters = ['RNN', '3x10']\n",
    "# filters = ['RNNHierarchical', '5x10']\n",
    "filters = []\n",
    "# max_step = 25000\n",
    "max_step = 25000\n",
    "units = ''\n",
    "num_rows = 2\n",
    "# units = 'thousands'\n",
    "\n",
    "meta_by_grammar_by_meanings_by_link = defaultdict(dict)\n",
    "last_refmodellinkmeanings = ''\n",
    "import matplotlib.pyplot as plt\n",
    "meta_by_grammar = {}\n",
    "grammars = []\n",
    "grammars_set = set()\n",
    "meta_by_grammar_by_rmlm = OrderedDict()\n",
    "\n",
    "for ref in refs:\n",
    "    e2e_logfiles = glob.glob(f'{log_dir}/log_{script}_{ref}_*.log')\n",
    "    for i, log_filepath in enumerate(e2e_logfiles):\n",
    "    #     print(file)\n",
    "    #     log_filepath = join(log_dir, file)\n",
    "        num_lines = graphing_common.get_num_lines(log_filepath)\n",
    "        if num_lines <= 3:\n",
    "    #         print('skipping', file)\n",
    "            continue\n",
    "        meta = graphing_common.read_meta(log_filepath)\n",
    "        meta['num_lines'] = num_lines\n",
    "        argv = meta['argv']\n",
    "        params = Params(meta['params'])\n",
    "        _ref = params.ref\n",
    "    #     print('ref', ref)\n",
    "        if _ref != ref:\n",
    "            continue\n",
    "    #     print('ref', ref)\n",
    "        meta['log_filepath'] = log_filepath\n",
    "        meanings = f'{params.num_meaning_types}x{params.meanings_per_type}'\n",
    "        grammar = params.grammar\n",
    "        if params.corruptions is not None and params.corruptions != '':\n",
    "            grammar = params.corruptions\n",
    "        if grammar not in grammars_set:\n",
    "            grammars.append(grammar)\n",
    "            grammars_set.add(grammar)\n",
    "        rmlm = f'{params.model}_{params.link}_{meanings}'\n",
    "        exclude = False\n",
    "        for filter in filters:\n",
    "            if filter not in rmlm:\n",
    "                exclude = True\n",
    "        if exclude:\n",
    "            continue\n",
    "        # check for timeouts\n",
    "        sup_lines = graphing_common.head(log_filepath, 3).split('\\n')[1:3]\n",
    "    #     print('sup_lines', sup_lines)\n",
    "        for line in sup_lines:\n",
    "            d = json.loads(line)\n",
    "    #         print(d['terminate_reason'])\n",
    "            if d['terminate_reason'] == 'timeout':\n",
    "                exclude = True\n",
    "                print('excluding for timeout', rmlm, grammar)\n",
    "        if exclude:\n",
    "            continue\n",
    "        if rmlm not in meta_by_grammar_by_rmlm:\n",
    "            meta_by_grammar_by_rmlm[rmlm] = {}\n",
    "        meta_by_grammar_by_rmlm[rmlm][grammar] = meta\n",
    "\n",
    "for rmlm, meta_by_grammar in meta_by_grammar_by_rmlm.items():\n",
    "    print(rmlm)\n",
    "    for grammar, meta in meta_by_grammar.items():\n",
    "        print('    ', grammar, meta['log_filepath'])\n",
    "\n",
    "for rmlm, meta_by_grammar in meta_by_grammar_by_rmlm.items():\n",
    "    plt.figure(figsize=(20, 3.5 * num_rows * num_rows))\n",
    "    plt.cla()\n",
    "    for j, value_key in enumerate(value_keys):\n",
    "        plt.subplot(num_rows, 4 // num_rows, j + 1)\n",
    "        for grammar in grammars:\n",
    "            if grammar not in meta_by_grammar:\n",
    "#                 print(f'warning {grammar} not found')\n",
    "                continue\n",
    "            meta = meta_by_grammar[grammar]\n",
    "            log_filepath = meta['log_filepath']\n",
    "            graphing.plot_logfile2(\n",
    "                log_filepath, step_key='episode', skip_record_types=['sup_train_res'], value_key=value_key,\n",
    "                label=grammar, title=value_key, max_step=max_step, units=units\n",
    "            )\n",
    "    print('')\n",
    "    print(' '.join(rmlm.split('_')[1:]))\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
