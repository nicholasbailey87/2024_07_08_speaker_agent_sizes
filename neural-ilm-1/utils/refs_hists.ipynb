{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics.cluster\n",
    "\n",
    "import torch\n",
    "\n",
    "# filename = 'hists/hypprop_with_predictor_eeb99_hughtok1_20180921_191657.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb100_hughtok2_20180921_193244.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb101_hughtok3_20180921_193516.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb102_hughtok4_20180921_193310.h5'\n",
    "\n",
    "# filename = 'hists/hypprop_with_predictor_eeb103_hughtok1_20180921_212947.h5'\n",
    "\n",
    "# filename = 'hists/hypprop_with_predictor_eeb105_hughtok5_20180921_230949.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb106_hughtok6_20180921_231010.h5'\n",
    "\n",
    "# filename = 'hists/hypprop_with_predictor_eeb107_hughtok2_20180922_013551.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb108_hughtok1_20180922_170013.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb109_hughtok2_20180922_184537.h5'\n",
    "# filename = 'hists/hypprop_with_predictor_eeb113_hughtok6_20180922_211153.h5'\n",
    "\n",
    "filename = 'hists/hypprop_with_predictor_eeb115_hughtok1_20180923_173818.h5'\n",
    "\n",
    "def create_ami_matrix(gnd, pred):\n",
    "    \"\"\"\n",
    "    assumptions:\n",
    "    - gnd and pred are 2d matrices\n",
    "    - gnd is [U_gnd][N]\n",
    "    - pred is [U_pred][N]\n",
    "    \"\"\"\n",
    "    U_gnd = gnd.size(0)\n",
    "    U_pred = pred.size(0)\n",
    "\n",
    "    ami_matrix = torch.zeros(U_pred, U_gnd)\n",
    "    for i in range(U_pred):\n",
    "        for j in range(U_gnd):\n",
    "            AMI = sklearn.metrics.cluster.adjusted_mutual_info_score(\n",
    "                labels_true=gnd[j].numpy(),\n",
    "                labels_pred=pred[i].numpy()\n",
    "            )\n",
    "            ami_matrix[i, j] = AMI\n",
    "    return ami_matrix\n",
    "\n",
    "def run():\n",
    "    shutil.copyfile(f'../{filename}', '/tmp/foo.h5')\n",
    "    # f = h5py.File('../hists/hypprop_with_predictor_eeb95_hughtok2_20180921_144419.h5', 'r')\n",
    "\n",
    "    f = h5py.File('/tmp/foo.h5', 'r')\n",
    "\n",
    "    print('f.keys()', f.keys())\n",
    "\n",
    "    hypotheses_train = torch.from_numpy(f['hypotheses_train'][:])\n",
    "    hypotheses_gnd_train = torch.from_numpy(f['gnd_hypotheses_train'][:].astype(np.uint8)).long()\n",
    "    dsrefs_train = torch.from_numpy(f['dsrefs_train'][:].astype(np.uint8)).long()\n",
    "    resdicts = f['resdicts']\n",
    "\n",
    "    print(hypotheses_train.shape)\n",
    "    print(hypotheses_gnd_train.shape)\n",
    "    print(dsrefs_train.shape)\n",
    "\n",
    "    N = dsrefs_train.size(0)\n",
    "    print('N', N)\n",
    "\n",
    "    num_renders = len(resdicts)\n",
    "\n",
    "    batch_size = 128\n",
    "\n",
    "    print('len(resdicts)', len(resdicts))\n",
    "    print('holdout dsrefs len', f['dsrefs_holdout'].shape[0])\n",
    "\n",
    "    num_dsrefs = dsrefs_train.max().item() + 1\n",
    "    print('num_dsrefs', num_dsrefs)\n",
    "    for dsref in range(num_dsrefs):\n",
    "        print('dsref', dsref)\n",
    "        start_render_id = 0\n",
    "        if num_renders > 100:\n",
    "            start_render_id = num_renders - 100\n",
    "        rows = (num_renders - start_render_id + 4) // 5\n",
    "        plt.figure(figsize=(20, 5 * rows))\n",
    "        for render_id in range(start_render_id, num_renders):\n",
    "            print('render_id', render_id)\n",
    "            b_start = render_id * batch_size\n",
    "            b_end = b_start + batch_size\n",
    "            _hypotheses_train = hypotheses_train[:, b_start:b_end]\n",
    "            _hypotheses_gnd_train = hypotheses_gnd_train[:, b_start:b_end]\n",
    "            _dsrefs_train = dsrefs_train[b_start:b_end]\n",
    "\n",
    "            dsref_idxes = (_dsrefs_train == dsref).view(-1).nonzero().view(-1).long()\n",
    "            _hypotheses_train = _hypotheses_train[:, dsref_idxes]\n",
    "            _hypotheses_gnd_train = _hypotheses_gnd_train[:, dsref_idxes]\n",
    "            \n",
    "            resdict = json.loads(resdicts[render_id])\n",
    "            episode = resdict['episode']\n",
    "\n",
    "            _, _pred = _hypotheses_train.max(dim=-1)\n",
    "            ami_matrix = create_ami_matrix(\n",
    "                gnd=_hypotheses_gnd_train,\n",
    "                pred=_pred\n",
    "            )\n",
    "    \n",
    "            r_acc1 = resdict['r_acc1']\n",
    "            plt.subplot(rows, 5, render_id - start_render_id + 1)\n",
    "            plt.imshow(ami_matrix.numpy())\n",
    "            plt.title(f'e={episode} r_acc1={r_acc1:.3f}')\n",
    "        plt.show()\n",
    "    f.close()\n",
    "\n",
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
