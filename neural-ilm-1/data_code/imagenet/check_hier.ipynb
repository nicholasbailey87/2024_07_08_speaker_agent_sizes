{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from collections import defaultdict\n",
    "import torch, json, time, csv\n",
    "import numpy as np\n",
    "import graphviz\n",
    "import pickle\n",
    "\n",
    "att_filepath = '../../data/imagenet/attrann.mat'\n",
    "\n",
    "# import scipy.io\n",
    "# mat = scipy.io.loadmat(att_filepath)\n",
    "# print('mat.keys()', mat.keys())\n",
    "# # print('mat[__globals__]', mat['__globals__'])\n",
    "# # print('mat[attrann].shape', mat['attrann'].shape)\n",
    "# # print('mat[attrann]', mat['attrann'])\n",
    "# # print('mat[attrann][0]', mat['attrann'][0])\n",
    "# print('mat[attrann][0][0]', mat['attrann'][0][0])\n",
    "# print('mat[attrann][0][0][0]', mat['attrann'][0][0][0])\n",
    "\n",
    "def vec_to_str(v):\n",
    "    K = v.size(0)\n",
    "#     v = v.clamp(min=0)\n",
    "    return ''.join([str(x) for x in v.tolist()])\n",
    "\n",
    "def print_bin_mat(mat):\n",
    "    rows, cols = mat.size()\n",
    "    for r in range(rows):\n",
    "        line = ''\n",
    "        for c in range(cols):\n",
    "            char = '*' if mat[r, c] == 0 else ' '\n",
    "            line += char\n",
    "        print(line)\n",
    "\n",
    "import mat4py\n",
    "mat = mat4py.loadmat(att_filepath)\n",
    "print('mat[attrann.keys()', mat['attrann'].keys())\n",
    "print('mat[attrann[images][:10]', mat['attrann']['images'][:10])\n",
    "print('len(mat[attrann[images])', len(mat['attrann']['images']))\n",
    "print('mat[attrann[attributes]', mat['attrann']['attributes'])\n",
    "print('len(mat[attrann[attributes])', len(mat['attrann']['labels']))\n",
    "print('len(mat[attrann[attributes][0])', len(mat['attrann']['labels'][0]))\n",
    "att_t = torch.LongTensor(mat['attrann']['labels'])\n",
    "att_t = att_t.clamp(min=0)\n",
    "print('att_t.size()', att_t.size())\n",
    "# print_bin_mat(att_t[:5])\n",
    "\n",
    "N, K = att_t.size()\n",
    "print('N', N, 'K', K)\n",
    "# values = torch.LongTensor(N)\n",
    "for n in range(5):\n",
    "    print(n, vec_to_str(att_t[n]))\n",
    "\n",
    "print('att_t.sum(dim=0)', att_t.sum(dim=0))    \n",
    "\n",
    "values_count = defaultdict(int)\n",
    "for n in range(N):\n",
    "    v_str = vec_to_str(att_t[n])\n",
    "    values_count[v_str] += 1\n",
    "\n",
    "print('len(values_count)', len(values_count))\n",
    "viable_sum = 0\n",
    "l = []\n",
    "for v, c in sorted(values_count.items()):\n",
    "    if c >= 4:\n",
    "        viable_sum += 1\n",
    "    print(v, c)\n",
    "    l.append((v, c))\n",
    "print('')\n",
    "l.sort(key=lambda x: x[1], reverse=True)\n",
    "for v, c in l:\n",
    "    print(v, c)\n",
    "print('')\n",
    "print('viable_sum', viable_sum)\n",
    "\n",
    "# for k in range(K):\n",
    "#     values = values * 2 + att_t[:, k]\n",
    "# print('values[:10]', values[:10])\n",
    "\n",
    "label_by_clsid = {}\n",
    "label_by_idtxt = {}\n",
    "with open('../../data/imagenet/map_clsloc.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        idtxt, clsid, label = line.split(' ')\n",
    "        label_by_clsid[int(clsid)] = label\n",
    "        label_by_idtxt[idtxt] = label\n",
    "for i in range(5):\n",
    "    print(i, label_by_clsid[i + 1])\n",
    "\n",
    "def load_imagenet():\n",
    "    with open('../../data/imagenet/val_data', 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "    print(d.keys())\n",
    "\n",
    "    print(d['labels'][:5])\n",
    "\n",
    "    img_size = 32\n",
    "\n",
    "    x = d['data']\n",
    "    y = d['labels']\n",
    "    # mean_image = d['mean']\n",
    "\n",
    "    x = x/np.float32(255)\n",
    "    # mean_image = mean_image/np.float32(255)\n",
    "\n",
    "    # Labels are indexed from 1, shift it so that indexes start at 0\n",
    "    y = [i-1 for i in y]\n",
    "    data_size = x.shape[0]\n",
    "\n",
    "    # x -= mean_image\n",
    "\n",
    "    img_size2 = img_size * img_size\n",
    "\n",
    "    x = np.dstack((x[:, :img_size2], x[:, img_size2:2*img_size2], x[:, 2*img_size2:]))\n",
    "    x = x.reshape((x.shape[0], img_size, img_size, 3)).transpose(0, 3, 1, 2)\n",
    "\n",
    "    # create mirrored images\n",
    "    X_train = x[0:data_size, :, :, :]\n",
    "    Y_train = y[0:data_size]\n",
    "    X_train_flip = X_train[:, :, :, ::-1]\n",
    "    Y_train_flip = Y_train\n",
    "    X_train = np.concatenate((X_train, X_train_flip), axis=0)\n",
    "    Y_train = np.concatenate((Y_train, Y_train_flip), axis=0)\n",
    "\n",
    "    print('X_train.shape', X_train.shape)\n",
    "    return X_train, Y_train\n",
    "\n",
    "X_train, Y_train = load_imagenet()\n",
    "\n",
    "def plot_image(img):\n",
    "    img = img.transpose(1,2,0)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    \n",
    "die()\n",
    "\n",
    "nodes = set()\n",
    "links = []\n",
    "with open('../../data/imagenet/wordnet.is_a.txt', 'r') as f:\n",
    "    for row in f:\n",
    "        row = row.strip()\n",
    "        p, n = row.split(' ')\n",
    "        links.append((p, n))\n",
    "        nodes.add(p)\n",
    "        nodes.add(n)\n",
    "print(links[:5])\n",
    "# print(contents[:100])\n",
    "print(list(nodes)[:5])\n",
    "\n",
    "synset_id_to_name = {}\n",
    "with open('../../data/imagenet/imagenet_label_to_wordnet_synset.txt', 'r') as f:\n",
    "    lookup = eval(f.read())\n",
    "#     lookup = json.loads(f.read().replace('\\'', '\"'))\n",
    "    for _, d in list(lookup.items()):\n",
    "        id, n = d['id'].split('-')\n",
    "        id = n + id\n",
    "        synset_id_to_name[id] = d['label']\n",
    "#         print(d['id'], d['label'])\n",
    "\n",
    "print(list(synset_id_to_name.items())[:5])\n",
    "\n",
    "dot = graphviz.Digraph('foobar')\n",
    "# for i in range(20):\n",
    "for node in list(nodes)[:10]:\n",
    "    dot.node(synset_id_to_name[node])\n",
    "\n",
    "#     if i > 0:\n",
    "#         dot.edge(f'a{i-1}', 'a{i}')\n",
    "dot.render()\n",
    "        \n",
    "# {0: {'id': '01440764-n',\n",
    "#      'label': 'tench, Tinca tinca',\n",
    "#      'uri': 'http://wordnet-rdf.princeton.edu/wn30/01440764-n'},\n",
    "#  1: {'id': '01443537-n',\n",
    "#      'label': 'goldfish, Carassius auratus',\n",
    "#      'uri': 'http://wordnet-rdf.princeton.edu/wn30/01443537-n'},\n",
    "#  2: {'id': '01484850-n',\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
